{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI Agent SDK Learning Path\n",
        "\n",
        "This notebook helps you explore the OpenAI Agent SDK capabilities step by step. Each section introduces one major feature with context, setup tips, and runnable Python snippets you can adapt to your workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook Roadmap\n",
        "\n",
        "- 0. Setup and environment checks\n",
        "- 1. Quick responses with the unified Responses API\n",
        "- 2. Structured outputs and JSON validation\n",
        "- 3. Function/tool calling fundamentals\n",
        "- 4. Building reusable agents with the Agent SDK\n",
        "- 5. Managing sessions and memory\n",
        "- 6. Streaming outputs and tracing\n",
        "- 7. Next steps and references\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup and Environment Checks\n",
        "\n",
        "Before running the code cells below, prepare your environment:\n",
        "\n",
        "- Python 3.10 or newer is recommended.\n",
        "- Verify that a `.env` file exists at the project root with `OPENAI_API_KEY` defined.\n",
        "- Create and activate the dedicated environment: `uv venv .venv-openai-agent && source .venv-openai-agent/bin/activate`.\n",
        "- Install dependencies: `uv pip install --python .venv-openai-agent/bin/python openai python-dotenv rich ipykernel`.\n",
        "- Register the kernel so Jupyter can see it: `.venv-openai-agent/bin/python -m ipykernel install --user --name civic-openai-agent --display-name \"civic OpenAI Agent\"`.\n",
        "- In Jupyter, choose `civic OpenAI Agent` from `Jupyter: Select Notebook Kernel` after reloading the window.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ… Dependencies are up to date.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU openai python-dotenv rich\n",
        "\n",
        "print(\"âœ… Dependencies are up to date.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Client automatically picks up OPENAI_API_KEY from the environment\n",
        "client = OpenAI()\n",
        "\n",
        "print(\"ðŸ¤– OpenAI client ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step-by-step solution:\n",
            "\n",
            "1. Write the multiplication in the usual vertical format:\n",
            "\n",
            "        25\n",
            "    x   47\n",
            "    ------\n",
            "    \n",
            "2. Multiply 25 by 7 (the ones digit of 47):\n",
            "   25 Ã— 7 = 175.\n",
            "   Write 175 under the line:\n",
            "\n",
            "        25\n",
            "    x   47\n",
            "    ------\n",
            "       175\n",
            "\n",
            "3. Next, multiply 25 by 40 (the tens digit of 47 is 4, but it represents 40):\n",
            "   25 Ã— 40 = 1000.\n",
            "   Write 1000 shifted one digit to the left (because it is in the tens place):\n",
            "\n",
            "        25\n",
            "    x   47\n",
            "    ------\n",
            "       175\n",
            "    1000\n",
            "\n",
            "4. Finally, add the two partial products:\n",
            "   175 + 1000 = 1175.\n",
            "\n",
            "So, 25 Ã— 47 = 1175.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()  # reads OPENAI_API_KEY from environment\n",
        "\n",
        "# Use reasoning model\n",
        "response = client.chat.completions.create(\n",
        "    model=\"o1\",  # or \"o1-mini\" or \"o1-preview\"\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Solve this problem step by step: What is 25 * 47?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available reasoning models: ['gpt-4-0613', 'gpt-4', 'gpt-3.5-turbo', 'gpt-5-search-api-2025-10-14', 'gpt-realtime-mini', 'gpt-realtime-mini-2025-10-06', 'sora-2', 'sora-2-pro', 'davinci-002', 'babbage-002', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'dall-e-3', 'dall-e-2', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'tts-1-hd', 'tts-1-1106', 'tts-1-hd-1106', 'text-embedding-3-small', 'text-embedding-3-large', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini', 'gpt-4o-2024-08-06', 'chatgpt-4o-latest', 'o1-mini-2024-09-12', 'o1-mini', 'gpt-4o-realtime-preview-2024-10-01', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview', 'gpt-4o-realtime-preview', 'omni-moderation-latest', 'omni-moderation-2024-09-26', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4o-mini-audio-preview-2024-12-17', 'o1-2024-12-17', 'o1', 'gpt-4o-mini-realtime-preview', 'gpt-4o-mini-audio-preview', 'o3-mini', 'o3-mini-2025-01-31', 'gpt-4o-2024-11-20', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-search-preview', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe', 'o1-pro-2025-03-19', 'o1-pro', 'gpt-4o-mini-tts', 'o3-2025-04-16', 'o4-mini-2025-04-16', 'o3', 'o4-mini', 'gpt-4.1-2025-04-14', 'gpt-4.1', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-nano-2025-04-14', 'gpt-4.1-nano', 'gpt-image-1', 'codex-mini-latest', 'gpt-4o-realtime-preview-2025-06-03', 'gpt-4o-audio-preview-2025-06-03', 'o4-mini-deep-research', 'gpt-4o-transcribe-diarize', 'o4-mini-deep-research-2025-06-26', 'gpt-5-chat-latest', 'gpt-5-2025-08-07', 'gpt-5', 'gpt-5-mini-2025-08-07', 'gpt-5-mini', 'gpt-5-nano-2025-08-07', 'gpt-5-nano', 'gpt-audio-2025-08-28', 'gpt-realtime', 'gpt-realtime-2025-08-28', 'gpt-audio', 'gpt-5-codex', 'gpt-image-1-mini', 'gpt-5-pro-2025-10-06', 'gpt-5-pro', 'gpt-audio-mini', 'gpt-audio-mini-2025-10-06', 'gpt-5-search-api', 'gpt-3.5-turbo-16k', 'tts-1', 'whisper-1', 'text-embedding-ada-002']\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# List available models to confirm access\n",
        "models = client.models.list()\n",
        "reasoning_models = [m.id for m in models.data]\n",
        "print(\"Available reasoning models:\", reasoning_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1175\n",
            "ChatCompletion(id='chatcmpl-CYfqfbHp2IJxoOqrKDfNFOadBhHap', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1175', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762380053, model='gpt-5-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=75, prompt_tokens=18, total_tokens=93, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=64, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()  # reads OPENAI_API_KEY from environment\n",
        "\n",
        "# Use reasoning model\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-5\",  # or \"o1-mini\" or \"o1-preview\"\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Solve this problem : What is 25 * 47?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Message attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_on_complete__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'annotations', 'audio', 'construct', 'content', 'copy', 'dict', 'from_orm', 'function_call', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'refusal', 'role', 'schema', 'schema_json', 'to_dict', 'to_json', 'tool_calls', 'update_forward_refs', 'validate']\n",
            "\n",
            "Message dict: {'content': '1175', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}\n"
          ]
        }
      ],
      "source": [
        "message = response.choices[0].message\n",
        "\n",
        "# Check all attributes\n",
        "print(\"Message attributes:\", dir(message))\n",
        "print(\"\\nMessage dict:\", message.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-agents\n",
            "  Using cached openai_agents-0.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Using cached griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting mcp<2,>=1.11.0 (from openai-agents)\n",
            "  Downloading mcp-1.20.0-py3-none-any.whl.metadata (85 kB)\n",
            "Requirement already satisfied: openai<3,>=2.7.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents) (2.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.12.3 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents) (2.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents) (2.32.4)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Using cached types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents) (4.14.1)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents) (4.11.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Collecting jsonschema>=4.20.0 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting python-multipart>=0.0.9 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading sse_starlette-3.0.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting starlette>=0.27 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting uvicorn>=0.31.1 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.11.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading rpds_py-0.28.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.2.1)\n",
            "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
            "Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pycparser in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (2.22)\n",
            "Collecting click>=7.0 (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Using cached openai_agents-0.5.0-py3-none-any.whl (223 kB)\n",
            "Using cached griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "Downloading mcp-1.20.0-py3-none-any.whl (173 kB)\n",
            "Using cached types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
            "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Downloading cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl (181 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.28.0-cp312-cp312-macosx_11_0_arm64.whl (348 kB)\n",
            "Downloading sse_starlette-3.0.3-py3-none-any.whl (11 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Installing collected packages: types-requests, rpds-py, python-multipart, pyjwt, httpx-sse, colorama, click, cffi, attrs, uvicorn, starlette, sse-starlette, referencing, griffe, cryptography, pydantic-settings, jsonschema-specifications, jsonschema, mcp, openai-agents\n",
            "\u001b[2K  Attempting uninstall: cffi\n",
            "\u001b[2K    Found existing installation: cffi 1.17.1\n",
            "\u001b[2K    Uninstalling cffi-1.17.1:\n",
            "\u001b[2K      Successfully uninstalled cffi-1.17.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/20\u001b[0m [cffi]\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20/20\u001b[0m [openai-agents]0m [openai-agents]\n",
            "\u001b[1A\u001b[2KSuccessfully installed attrs-25.4.0 cffi-2.0.0 click-8.3.0 colorama-0.4.6 cryptography-46.0.3 griffe-1.14.0 httpx-sse-0.4.3 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 mcp-1.20.0 openai-agents-0.5.0 pydantic-settings-2.11.0 pyjwt-2.10.1 python-multipart-0.0.20 referencing-0.37.0 rpds-py-0.28.0 sse-starlette-3.0.3 starlette-0.50.0 types-requests-2.32.4.20250913 uvicorn-0.38.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: openai-agents[voice] in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (0.5.0)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (1.14.0)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (1.20.0)\n",
            "Requirement already satisfied: openai<3,>=2.7.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (2.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.12.3 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (2.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (2.32.4)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (4.14.1)\n",
            "Requirement already satisfied: numpy<3,>=2.2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[voice]) (2.2.6)\n",
            "Collecting websockets<16,>=15.0 (from openai-agents[voice])\n",
            "  Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from griffe<2,>=1.5.6->openai-agents[voice]) (0.4.6)\n",
            "Requirement already satisfied: anyio>=4.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (4.11.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (0.4.3)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (2.11.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[voice]) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (0.50.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[voice]) (0.38.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[voice]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[voice]) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[voice]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[voice]) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.11.0->openai-agents[voice]) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[voice]) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[voice]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[voice]) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[voice]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[voice]) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[voice]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents[voice]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents[voice]) (2.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[voice]) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[voice]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[voice]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[voice]) (0.28.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents[voice]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[voice]) (46.0.3)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[voice]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[voice]) (2.22)\n",
            "Requirement already satisfied: click>=7.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents[voice]) (8.3.0)\n",
            "Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Installing collected packages: websockets\n",
            "Successfully installed websockets-15.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: openai-agents[redis] in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (0.5.0)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (1.14.0)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (1.20.0)\n",
            "Requirement already satisfied: openai<3,>=2.7.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (2.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.12.3 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (2.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (2.32.4)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai-agents[redis]) (4.14.1)\n",
            "Collecting redis>=6.4.0 (from openai-agents[redis])\n",
            "  Using cached redis-7.0.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from griffe<2,>=1.5.6->openai-agents[redis]) (0.4.6)\n",
            "Requirement already satisfied: anyio>=4.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (4.11.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (0.4.3)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (2.11.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[redis]) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (0.50.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from mcp<2,>=1.11.0->openai-agents[redis]) (0.38.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[redis]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[redis]) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[redis]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from openai<3,>=2.7.1->openai-agents[redis]) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.11.0->openai-agents[redis]) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[redis]) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[redis]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents[redis]) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[redis]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[redis]) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic<3,>=2.12.3->openai-agents[redis]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents[redis]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents[redis]) (2.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[redis]) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[redis]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[redis]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[redis]) (0.28.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents[redis]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[redis]) (46.0.3)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[redis]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents[redis]) (2.22)\n",
            "Requirement already satisfied: click>=7.0 in /Users/ali/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents[redis]) (8.3.0)\n",
            "Using cached redis-7.0.1-py3-none-any.whl (339 kB)\n",
            "Installing collected packages: redis\n",
            "Successfully installed redis-7.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Basic installation\n",
        "!pip install openai-agents\n",
        "\n",
        "# With voice support\n",
        "!pip install 'openai-agents[voice]'\n",
        "\n",
        "# With Redis session support\n",
        "!pip install 'openai-agents[redis]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-agents -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Code flows, crisp and clear  \n",
            "Indentation whispers truthâ€”  \n",
            "Python breathes with ease.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "# Create the simplest possible agent\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\"\n",
        ")\n",
        "\n",
        "# In Jupyter, use 'await Runner.run()' not 'Runner.run_sync()'\n",
        "result = await Runner.run(agent, \"Write a haiku about Python programming.\")\n",
        "\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Result Object ===\n",
            "Final Output: RunResult:\n",
            "- Last agent: Agent(name=\"Helper\", ...)\n",
            "- Final output (str):\n",
            "    2 + 2 = 4\n",
            "- 1 new item(s)\n",
            "- 1 raw response(s)\n",
            "- 0 input guardrail result(s)\n",
            "- 0 output guardrail result(s)\n",
            "(See `RunResult` for more details)\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Helper\",\n",
        "    instructions=\"Be concise and helpful.\"\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"What is 2 + 2?\")\n",
        "\n",
        "# Explore what's in the result\n",
        "print(\"=== Result Object ===\")\n",
        "print(f\"Final Output: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing tool directly:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'FunctionTool' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Test the tool directly\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting tool directly:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m5 Ã— 7 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mTypeError\u001b[39m: 'FunctionTool' object is not callable"
          ]
        }
      ],
      "source": [
        "from agents import function_tool\n",
        "\n",
        "# Define a simple tool\n",
        "@function_tool\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers together\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# Test the tool directly\n",
        "print(\"Testing tool directly:\")\n",
        "print(f\"5 Ã— 7 = {multiply(5, 7)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 times 47 is 1175.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers together\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# Create agent with the tool\n",
        "math_agent = Agent(\n",
        "    name=\"Math Agent\",\n",
        "    instructions=\"You are a helpful math assistant. Use your tools when needed.\",\n",
        "    tools=[multiply]  # Give the agent access to the multiply function\n",
        ")\n",
        "\n",
        "# Ask the agent to multiply\n",
        "result = await Runner.run(math_agent, \"What is 25 times 47?\")\n",
        "\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 + 30 equals 45.\n",
            "The weather in Seattle is currently rainy with a temperature of 55Â°F.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@function_tool\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the weather for a city\"\"\"\n",
        "    # This is a mock - in real life you'd call a weather API\n",
        "    weather_data = {\n",
        "        \"Seattle\": \"Rainy, 55Â°F\",\n",
        "        \"Miami\": \"Sunny, 85Â°F\",\n",
        "        \"New York\": \"Cloudy, 60Â°F\"\n",
        "    }\n",
        "    return weather_data.get(city, \"Weather data not available\")\n",
        "\n",
        "# Agent with multiple tools\n",
        "agent = Agent(\n",
        "    name=\"Multi-Tool Agent\",\n",
        "    instructions=\"You are helpful. Use your tools when appropriate.\",\n",
        "    tools=[add, multiply, get_weather]\n",
        ")\n",
        "\n",
        "# Test it\n",
        "result = await Runner.run(\n",
        "    agent,\n",
        "    \"What's 15 + 30? Also, what's the weather in Seattle?\"\n",
        ")\n",
        "\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Created agent named: Assistant\n"
          ]
        }
      ],
      "source": [
        "# Create an agent with a name and instructions\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\"\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Created agent named: {agent.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Call itself anewâ€”  \n",
            "The answer within the call,  \n",
            "Endless loop of thought.\n"
          ]
        }
      ],
      "source": [
        "# Ask the agent a question\n",
        "result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
        "\n",
        "# Print what the agent said\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolutely! Hereâ€™s a very simple explanation:\n",
            "\n",
            "**Recursion** is when something refers to itself.\n",
            "\n",
            "In math, **recursion** usually means a process where a problem is solved by breaking it down into smaller versions of the same problem.\n",
            "\n",
            "**An example:**\n",
            "Think about counting down from 5.\n",
            "\n",
            "- First, you say 5,\n",
            "- Then you count down from 4,  \n",
            "- Then from 3,\n",
            "- Then from 2,\n",
            "- Then from 1.\n",
            "\n",
            "You can see: to count down from any number, you count down from the number just before it.\n",
            "\n",
            "**In other words:**  \n",
            "To count down from N:  \n",
            "- Say N,  \n",
            "- Then count down from N-1.\n",
            "\n",
            "This is **recursive** â€” the \"countdown\" process repeats itself, just with a smaller number each time.\n",
            "\n",
            "**In computers,** recursion is when a function (a little recipe) calls itself to solve a problem.\n",
            "\n",
            "**Summary:**  \n",
            "Recursion means \"do the same process again, but on a simpler/smaller version of the problem,\" until you reach something so simple you can solve it right away.\n"
          ]
        }
      ],
      "source": [
        "# Create a new agent with different instructions\n",
        "agent = Agent(\n",
        "    name=\"Math Helper\",\n",
        "    instructions=\"You explain math concepts in very simple terms.\"\n",
        ")\n",
        "\n",
        "# Ask a question\n",
        "result = await Runner.run(agent, \"What is recursion?\")\n",
        "\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Created weather tool\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "# The @function_tool decorator turns a Python function into a tool\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the current weather for a city.\"\"\"\n",
        "    # For now, we'll return fake data\n",
        "    # In real life, you'd call a weather API here\n",
        "    return f\"The weather in {city} is sunny and 20Â°C.\"\n",
        "\n",
        "print(\"âœ“ Created weather tool\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Agent created with weather tool\n"
          ]
        }
      ],
      "source": [
        "# Create an agent WITH a tool\n",
        "agent = Agent(\n",
        "    name=\"Weather Assistant\",\n",
        "    instructions=\"You are a helpful assistant.\",\n",
        "    tools=[get_weather]  # <-- This is the important part!\n",
        ")\n",
        "\n",
        "print(\"âœ“ Agent created with weather tool\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The weather in Tokyo is currently sunny with a temperature of 20Â°C.\n"
          ]
        }
      ],
      "source": [
        "result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
        "\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Agent created\n",
            "Type: <class 'agents.agent.Agent'>\n",
            "Agent name: BasicBot\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "# Create the simplest agent\n",
        "agent = Agent(\n",
        "    name=\"BasicBot\",\n",
        "    instructions=\"You are helpful.\"\n",
        ")\n",
        "\n",
        "print(\"âœ“ Agent created\")\n",
        "print(f\"Type: {type(agent)}\")\n",
        "print(f\"Agent name: {agent.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Agent Attributes ===\n",
            "name: Explorer\n",
            "instructions: You are helpful.\n",
            "tools: []\n",
            "model: None\n",
            "handoffs: []\n"
          ]
        }
      ],
      "source": [
        "# Create an agent\n",
        "agent = Agent(\n",
        "    name=\"Explorer\",\n",
        "    instructions=\"You are helpful.\"\n",
        ")\n",
        "\n",
        "# Check all the main attributes\n",
        "print(\"=== Agent Attributes ===\")\n",
        "print(f\"name: {agent.name}\")\n",
        "print(f\"instructions: {agent.instructions}\")\n",
        "print(f\"tools: {agent.tools}\")\n",
        "print(f\"model: {agent.model}\")\n",
        "print(f\"handoffs: {agent.handoffs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short instructions result: Programming\n",
            "\n",
            "Detailed instructions result: **Python** is a high-level, interpreted programming language that is widely used for various types of software development, including web development, data analysis, artificial intelligence, scientific computing, automation, and more. It was created by **Guido van Rossum** and was first released in 1991.\n",
            "\n",
            "---\n",
            "\n",
            "## Key Features of Python\n",
            "\n",
            "1. **Easy to Read and Write**\n",
            "   - Python code is designed to be readable and straightforward. It uses indentation to define code blocks, which makes the structure of the code clear.\n",
            "   - Example:\n",
            "     ```python\n",
            "     print(\"Hello, world!\")\n",
            "     ```\n",
            "\n",
            "2. **Interpreted Language**\n",
            "   - You do not need to compile Python code before running it. The Python interpreter reads and executes the code line by line.\n",
            "   \n",
            "3. **Dynamically Typed**\n",
            "   - You donâ€™t need to declare the type of a variable in advance. Python automatically assigns data types based on the value you assign.\n",
            "   - Example:\n",
            "     ```python\n",
            "     x = 10        # x is an integer\n",
            "     x = \"hello\"   # now x is a string\n",
            "     ```\n",
            "\n",
            "4. **Object-Oriented**\n",
            "   - Python supports object-oriented programming (OOP), which allows you to create and use classes and objects.\n",
            "   - Example:\n",
            "     ```python\n",
            "     class Dog:\n",
            "         def __init__(self, name):\n",
            "             self.name = name\n",
            "         def bark(self):\n",
            "             print(self.name + \" says Woof!\")\n",
            "     \n",
            "     my_dog = Dog(\"Buddy\")\n",
            "     my_dog.bark()   # Output: Buddy says Woof!\n",
            "     ```\n",
            "\n",
            "5. **Extensive Standard Library**\n",
            "   - Python includes a lot of built-in modules and libraries that help you perform various tasks without having to write everything from scratch.\n",
            "   - Example: `math`, `random`, `os`, etc.\n",
            "\n",
            "6. **Large Community and Open Source**\n",
            "   - Python is free to use and has a massive community, which means lots of tutorials, third-party libraries, and support are available.\n",
            "\n",
            "---\n",
            "\n",
            "## Where is Python Used?\n",
            "\n",
            "- **Web Development**: Creating websites and web applications (using frameworks like Django and Flask).\n",
            "- **Data Science & Machine Learning**: Analyzing data, building AI models (with packages like Pandas, NumPy, TensorFlow).\n",
            "- **Scripting and Automation**: Automating repetitive tasks on your computer.\n",
            "- **Software Development**: Building desktop and mobile apps.\n",
            "- **Game Development**: Creating simple games (using libraries like Pygame).\n",
            "\n",
            "---\n",
            "\n",
            "## Example: Simple Python Program\n",
            "\n",
            "Hereâ€™s a basic program that asks for your name and greets you:\n",
            "\n",
            "```python\n",
            "name = input(\"What is your name? \")\n",
            "print(\"Hello, \" + name + \"!\")\n",
            "```\n",
            "**How it works:**\n",
            "1. `input()` prompts the user to enter something.\n",
            "2. The program reads what you type and stores it in the variable `name`.\n",
            "3. `print()` displays a greeting using the name you entered.\n",
            "\n",
            "---\n",
            "\n",
            "## Summary\n",
            "**Python** is a beginner-friendly, powerful, and versatile programming language. Its simple syntax and broad applicability make it a great choice for both beginners and professionals.\n",
            "\n",
            "If you need more specific examples or want to know how to install Python, let me know!\n"
          ]
        }
      ],
      "source": [
        "# Agent with short instructions\n",
        "agent1 = Agent(\n",
        "    name=\"ShortBot\",\n",
        "    instructions=\"Reply in one word only.\"\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent1, \"What is Python?\")\n",
        "print(\"Short instructions result:\", result.final_output)\n",
        "\n",
        "# Agent with detailed instructions  \n",
        "agent2 = Agent(\n",
        "    name=\"DetailBot\",\n",
        "    instructions=\"You are a teacher. Explain everything in detail with examples.\"\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent2, \"What is Python?\")\n",
        "print(\"\\nDetailed instructions result:\", result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default model: None\n",
            "Specific model: gpt-4o-mini\n",
            "\n",
            "Response from gpt-4o-mini: Hi there! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "# Using different models\n",
        "agent_default = Agent(\n",
        "    name=\"DefaultModel\",\n",
        "    instructions=\"You are helpful.\"\n",
        "    # model not specified - uses default\n",
        ")\n",
        "\n",
        "agent_specific = Agent(\n",
        "    name=\"SpecificModel\", \n",
        "    instructions=\"You are helpful.\",\n",
        "    model=\"gpt-4o-mini\"  # Faster, cheaper model\n",
        ")\n",
        "\n",
        "print(f\"Default model: {agent_default.model}\")\n",
        "print(f\"Specific model: {agent_specific.model}\")\n",
        "\n",
        "# Test both\n",
        "result = await Runner.run(agent_specific, \"Say hi!\")\n",
        "print(f\"\\nResponse from {agent_specific.model}:\", result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tools: 1\n",
            "Tool names: ['calculator']\n",
            "First tool: FunctionTool(name='calculator', description='Add two numbers.', params_json_schema={'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'calculator_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x112d377e0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)\n"
          ]
        }
      ],
      "source": [
        "from agents import function_tool\n",
        "\n",
        "@function_tool\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"MathBot\",\n",
        "    instructions=\"You help with math.\",\n",
        "    tools=[calculator]  # List of tools\n",
        ")\n",
        "\n",
        "print(f\"Number of tools: {len(agent.tools)}\")\n",
        "print(f\"Tool names: {[tool.name for tool in agent.tools]}\")\n",
        "print(f\"First tool: {agent.tools[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! ðŸ˜Š How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from agents import RunContextWrapper\n",
        "\n",
        "def dynamic_instructions(run_context: RunContextWrapper, agent: Agent) -> str:\n",
        "    \"\"\"This function generates instructions dynamically.\"\"\"\n",
        "    return \"You are a helpful assistant. Be very friendly!\"\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"DynamicBot\",\n",
        "    instructions=dynamic_instructions  # Function, not string!\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"Hello!\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original name: Original\n",
            "Cloned name: Cloned\n",
            "Original instructions: You are helpful.\n",
            "Cloned instructions: You are VERY helpful and enthusiastic!\n",
            "\n",
            "Cloned response: Hi there! ðŸ‘‹ðŸ˜Š I'm so excited to chat with you! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "# Original agent\n",
        "original = Agent(\n",
        "    name=\"Original\",\n",
        "    instructions=\"You are helpful.\"\n",
        ")\n",
        "\n",
        "# Clone with changes\n",
        "cloned = original.clone(\n",
        "    name=\"Cloned\",\n",
        "    instructions=\"You are VERY helpful and enthusiastic!\"\n",
        ")\n",
        "\n",
        "print(f\"Original name: {original.name}\")\n",
        "print(f\"Cloned name: {cloned.name}\")\n",
        "print(f\"Original instructions: {original.instructions}\")\n",
        "print(f\"Cloned instructions: {cloned.instructions}\")\n",
        "\n",
        "# Test the clone\n",
        "result = await Runner.run(cloned, \"Say hi\")\n",
        "print(f\"\\nCloned response: {result.final_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static: Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "# Static instructions - same every time\n",
        "agent_static = Agent(\n",
        "    name=\"StaticBot\",\n",
        "    instructions=\"You are helpful.\"  # This NEVER changes\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent_static, \"Hello\")\n",
        "print(\"Static:\", result.final_output)\n",
        "\n",
        "# Problem: What if you want instructions to change based on:\n",
        "# - Time of day\n",
        "# - User preferences  \n",
        "# - Context from previous interactions\n",
        "# That's why dynamic instructions exist!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Dynamic instructions function was called!\n",
            "Hi there! ðŸ˜Š How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner, RunContextWrapper\n",
        "\n",
        "# This function gets called EVERY TIME the agent runs\n",
        "def dynamic_instructions(run_context: RunContextWrapper, agent: Agent) -> str:\n",
        "    \"\"\"\n",
        "    This function is called before the agent responds.\n",
        "    It GENERATES the instructions at runtime.\n",
        "    \n",
        "    Parameters:\n",
        "    - run_context: Contains information about the current run\n",
        "    - agent: The agent itself\n",
        "    \n",
        "    Returns:\n",
        "    - A string with instructions\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”„ Dynamic instructions function was called!\")\n",
        "    return \"You are a helpful assistant. Be very friendly!\"\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"DynamicBot\",\n",
        "    instructions=dynamic_instructions  # Pass the FUNCTION, not a string\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"Say hi\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Generating instructions for Alice who is happy\n",
            "\n",
            "ðŸ˜Š HAPPY MODE: Absolutely, Alice! ðŸâœ¨\n",
            "\n",
            "**Python** is a super popular programming language thatâ€™s loved for being easy to read and write. Here are some fun facts:\n",
            "\n",
            "- **Beginner-Friendly:** Its simple syntax makes it a favorite for newbies and pros alike!\n",
            "- **Versatile:** Itâ€™s used in web development, data science, automation, artificial intelligence, and way more!\n",
            "- **Huge Community:** Tons of libraries and helpful folks online!\n",
            "- **Cross-Platform:** Works on Windows, Mac, and Linux.\n",
            "\n",
            "If you want, I can give you some example code or help you get started! ðŸ’»ðŸŽ‰\n",
            "ðŸ“‹ Generating instructions for Bob who is serious\n",
            "\n",
            "ðŸŽ© SERIOUS MODE: Certainly, Bob.\n",
            "\n",
            "**Python** is a high-level, interpreted programming language known for its simplicity, readability, and versatility. It was created by Guido van Rossum and first released in 1991. Python emphasizes code readability and allows developers to express concepts in fewer lines of code compared to languages such as C++ or Java.\n",
            "\n",
            "**Key Features of Python:**\n",
            "- **Easy to Learn and Use:** The syntax is straightforward, making it accessible for beginners and efficient for experienced programmers.\n",
            "- **Interpreted Language:** Python code is executed line by line, simplifying debugging and development.\n",
            "- **Dynamically Typed:** Variable types are determined at runtime, adding flexibility.\n",
            "- **Extensive Standard Library:** Python includes a large collection of modules and packages to perform a wide variety of tasks.\n",
            "- **Cross-platform:** Python runs on various operating systems, including Windows, macOS, and Linux.\n",
            "- **Community Support:** It has a large, active community that contributes to its development and maintenance.\n",
            "\n",
            "**Common Uses of Python:**\n",
            "- **Web Development** (using frameworks such as Django and Flask)\n",
            "- **Data Science and Machine Learning** (with libraries like NumPy, pandas, scikit-learn, TensorFlow, and PyTorch)\n",
            "- **Automation and Scripting**\n",
            "- **Software Prototyping**\n",
            "- **Network Programming**\n",
            "- **Game Development**\n",
            "\n",
            "Python is widely adopted in both academia and industry due to its ease of use and powerful capabilities. It is an excellent language for both beginners and seasoned software professionals.\n",
            "\n",
            "If you would like details on any specific aspect of Python or its applications, please let me know.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner, RunContextWrapper\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "\n",
        "# Define custom context data\n",
        "@dataclass\n",
        "class MyContext:\n",
        "    mood: str  # \"happy\" or \"serious\"\n",
        "    user_name: str\n",
        "\n",
        "# Dynamic instructions that use the context\n",
        "def dynamic_instructions(run_context: RunContextWrapper[MyContext], agent: Agent) -> str:\n",
        "    # Access the context data\n",
        "    mood = run_context.context.mood\n",
        "    user_name = run_context.context.user_name\n",
        "    \n",
        "    print(f\"ðŸ“‹ Generating instructions for {user_name} who is {mood}\")\n",
        "    \n",
        "    if mood == \"happy\":\n",
        "        return f\"You are a cheerful assistant talking to {user_name}. Use emojis!\"\n",
        "    else:\n",
        "        return f\"You are a professional assistant talking to {user_name}. Be formal.\"\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"ContextAwareBot\",\n",
        "    instructions=dynamic_instructions\n",
        ")\n",
        "\n",
        "# Run with happy context\n",
        "context_happy = MyContext(mood=\"happy\", user_name=\"Alice\")\n",
        "result = await Runner.run(agent, \"Tell me about Python\", context=context_happy)\n",
        "print(\"\\nðŸ˜Š HAPPY MODE:\", result.final_output)\n",
        "\n",
        "# Run with serious context\n",
        "context_serious = MyContext(mood=\"serious\", user_name=\"Bob\")\n",
        "result = await Runner.run(agent, \"Tell me about Python\", context=context_serious)\n",
        "print(\"\\nðŸŽ© SERIOUS MODE:\", result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ALL AGENT ATTRIBUTES ===\n",
            "\n",
            "handoff_description: None\n",
            "handoffs: []\n",
            "hooks: None\n",
            "input_guardrails: []\n",
            "instructions: You are helpful.\n",
            "mcp_config: {}\n",
            "mcp_servers: []\n",
            "model: gpt-4o-mini\n",
            "model_settings: ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None)\n",
            "name: ExplorerBot\n",
            "output_guardrails: []\n",
            "output_type: None\n",
            "prompt: None\n",
            "reset_tool_choice: True\n",
            "tool_use_behavior: run_llm_again\n",
            "tools: []\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent\n",
        "import inspect\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"ExplorerBot\",\n",
        "    instructions=\"You are helpful.\",\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "print(\"=== ALL AGENT ATTRIBUTES ===\\n\")\n",
        "\n",
        "# Get all attributes and methods\n",
        "for name in dir(agent):\n",
        "    # Skip private/internal attributes\n",
        "    if name.startswith('_'):\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        value = getattr(agent, name)\n",
        "        \n",
        "        # Skip methods (functions)\n",
        "        if callable(value):\n",
        "            continue\n",
        "            \n",
        "        print(f\"{name}: {value}\")\n",
        "    except:\n",
        "        print(f\"{name}: <unable to access>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== AGENT PROPERTIES AS DICT ===\n",
            "\n",
            "name: DictBot\n",
            "instructions: You are helpful.\n",
            "model: gpt-4o-mini\n",
            "tools_count: 0\n",
            "handoffs_count: 0\n",
            "has_output_type: False\n",
            "has_model_settings: True\n",
            "has_hooks: False\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, ModelSettings\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"DictBot\",\n",
        "    instructions=\"You are helpful.\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_settings=ModelSettings(temperature=0.8)\n",
        ")\n",
        "\n",
        "# Try to convert to dict-like representation\n",
        "print(\"=== AGENT PROPERTIES AS DICT ===\\n\")\n",
        "\n",
        "agent_props = {\n",
        "    'name': agent.name,\n",
        "    'instructions': agent.instructions,\n",
        "    'model': agent.model,\n",
        "    'tools_count': len(agent.tools),\n",
        "    'handoffs_count': len(agent.handoffs),\n",
        "    'has_output_type': agent.output_type is not None,\n",
        "    'has_model_settings': agent.model_settings is not None,\n",
        "    'has_hooks': agent.hooks is not None,\n",
        "}\n",
        "\n",
        "for key, value in agent_props.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŸ¢ Agent HookedBot STARTED\n",
            "ðŸ”§ Tool calculator STARTING\n",
            "âœ… Tool calculator FINISHED\n",
            "   Result: 15\n",
            "ðŸ”´ Agent HookedBot ENDED\n",
            "   Output: 5 + 10 equals 15.\n",
            "\n",
            "ðŸ“ Final answer: 5 + 10 equals 15.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, AgentHooks, RunContextWrapper, Runner, Tool, function_tool\n",
        "\n",
        "class MyHooks(AgentHooks):\n",
        "    \"\"\"Monitor what the agent does.\"\"\"\n",
        "    \n",
        "    async def on_start(self, context: RunContextWrapper, agent: Agent):\n",
        "        print(f\"ðŸŸ¢ Agent {agent.name} STARTED\")\n",
        "    \n",
        "    async def on_end(self, context: RunContextWrapper, agent: Agent, output):\n",
        "        print(f\"ðŸ”´ Agent {agent.name} ENDED\")\n",
        "        print(f\"   Output: {output}\")\n",
        "    \n",
        "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool):\n",
        "        print(f\"ðŸ”§ Tool {tool.name} STARTING\")\n",
        "    \n",
        "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, result: str):\n",
        "        # FIX: result might not be a string, so convert it first\n",
        "        result_str = str(result)\n",
        "        print(f\"âœ… Tool {tool.name} FINISHED\")\n",
        "        print(f\"   Result: {result_str}\")\n",
        "\n",
        "@function_tool\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"HookedBot\",\n",
        "    instructions=\"You help with math.\",\n",
        "    tools=[calculator],\n",
        "    hooks=MyHooks()\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"What is 5 + 10?\")\n",
        "print(f\"\\nðŸ“ Final answer: {result.final_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŸ¢ Agent HookedBot STARTED\n",
            "ðŸ”§ Tool calculator STARTING\n",
            "âœ… Tool calculator FINISHED\n",
            "   Result: 15\n",
            "ðŸ”´ Agent HookedBot ENDED\n",
            "   Output: 5 + 10 is 15.\n",
            "\n",
            "ðŸ“ Final answer: 5 + 10 is 15.\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, AgentHooks, RunContextWrapper, Runner, Tool, function_tool\n",
        "\n",
        "class MyHooks(AgentHooks):\n",
        "    \"\"\"Monitor what the agent does.\"\"\"\n",
        "    \n",
        "    async def on_start(self, context: RunContextWrapper, agent: Agent):\n",
        "        print(f\"ðŸŸ¢ Agent {agent.name} STARTED\")\n",
        "    \n",
        "    async def on_end(self, context: RunContextWrapper, agent: Agent, output):\n",
        "        print(f\"ðŸ”´ Agent {agent.name} ENDED\")\n",
        "        print(f\"   Output: {output}\")\n",
        "    \n",
        "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool):\n",
        "        print(f\"ðŸ”§ Tool {tool.name} STARTING\")\n",
        "    \n",
        "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, result: str):\n",
        "        # FIX: result might not be a string, so convert it first\n",
        "        result_str = str(result)\n",
        "        print(f\"âœ… Tool {tool.name} FINISHED\")\n",
        "        print(f\"   Result: {result_str}\")\n",
        "\n",
        "@function_tool\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"HookedBot\",\n",
        "    instructions=\"You help with math.\",\n",
        "    tools=[calculator],\n",
        "    hooks=MyHooks()\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"What is 5 + 10?\")\n",
        "print(f\"\\nðŸ“ Final answer: {result.final_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "METHOD 1: INSTRUCTIONS (Simple)\n",
            "==================================================\n",
            "Instructions: You are a helpful assistant who speaks casually.\n",
            "Prompt: None\n",
            "â†’ Instructions are embedded in the code\n",
            "\n",
            "\n",
            "METHOD 2: PROMPT (Advanced)\n",
            "==================================================\n",
            "Instructions: None\n",
            "Prompt: {'id': 'pmpt_xyz789', 'version': '2', 'variables': {'tone': 'professional', 'language': 'English'}}\n",
            "â†’ Instructions are stored remotely on OpenAI platform\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent\n",
        "\n",
        "print(\"METHOD 1: INSTRUCTIONS (Simple)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "agent1 = Agent(\n",
        "    name=\"SimpleBot\",\n",
        "    instructions=\"You are a helpful assistant who speaks casually.\"\n",
        "    # â†‘ The instructions are RIGHT HERE in the code\n",
        ")\n",
        "\n",
        "print(f\"Instructions: {agent1.instructions}\")\n",
        "print(f\"Prompt: {agent1.prompt}\")\n",
        "print(\"â†’ Instructions are embedded in the code\\n\")\n",
        "\n",
        "print(\"\\nMETHOD 2: PROMPT (Advanced)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "agent2 = Agent(\n",
        "    name=\"AdvancedBot\",\n",
        "    prompt={\n",
        "        \"id\": \"pmpt_xyz789\",\n",
        "        \"version\": \"2\",\n",
        "        \"variables\": {\n",
        "            \"tone\": \"professional\",\n",
        "            \"language\": \"English\"\n",
        "        }\n",
        "    }\n",
        "    # â†‘ This references a prompt stored on OpenAI's servers\n",
        ")\n",
        "\n",
        "print(f\"Instructions: {agent2.instructions}\")\n",
        "print(f\"Prompt: {agent2.prompt}\")\n",
        "print(\"â†’ Instructions are stored remotely on OpenAI platform\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating agent with 5 tools and PARALLEL CALLING enabled...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, AgentHooks, RunContextWrapper, Runner, Tool, function_tool, ModelSettings\n",
        "import asyncio\n",
        "import time\n",
        "\n",
        "# Track everything that happens\n",
        "events = []\n",
        "\n",
        "class DetailedHooks(AgentHooks):\n",
        "    \"\"\"Track every event with timestamps.\"\"\"\n",
        "    \n",
        "    async def on_start(self, context: RunContextWrapper, agent: Agent):\n",
        "        timestamp = time.strftime(\"%H:%M:%S\")\n",
        "        msg = f\"[{timestamp}] ðŸŸ¢ AGENT STARTED: {agent.name}\"\n",
        "        events.append(msg)\n",
        "        print(msg)\n",
        "    \n",
        "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool):\n",
        "        timestamp = time.strftime(\"%H:%M:%S\")\n",
        "        msg = f\"[{timestamp}] ðŸ”§ TOOL STARTED: {tool.name}\"\n",
        "        events.append(msg)\n",
        "        print(msg)\n",
        "    \n",
        "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, result: str):\n",
        "        timestamp = time.strftime(\"%H:%M:%S\")\n",
        "        msg = f\"[{timestamp}] âœ… TOOL FINISHED: {tool.name} â†’ {str(result)[:50]}\"\n",
        "        events.append(msg)\n",
        "        print(msg)\n",
        "    \n",
        "    async def on_end(self, context: RunContextWrapper, agent: Agent, output):\n",
        "        timestamp = time.strftime(\"%H:%M:%S\")\n",
        "        msg = f\"[{timestamp}] ðŸ”´ AGENT ENDED\"\n",
        "        events.append(msg)\n",
        "        print(msg)\n",
        "\n",
        "# Create 5 different tools\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a city.\"\"\"\n",
        "    time.sleep(0.5)  # Simulate API call delay\n",
        "    return f\"Weather in {city}: Sunny, 20Â°C\"\n",
        "\n",
        "@function_tool\n",
        "def get_time(city: str) -> str:\n",
        "    \"\"\"Get current time in a city.\"\"\"\n",
        "    time.sleep(0.3)  # Simulate API call delay\n",
        "    return f\"Time in {city}: 3:00 PM\"\n",
        "\n",
        "@function_tool\n",
        "def calculate_sum(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    time.sleep(0.2)  # Simulate computation\n",
        "    return a + b\n",
        "\n",
        "@function_tool\n",
        "def calculate_product(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    time.sleep(0.4)  # Simulate computation\n",
        "    return a * b\n",
        "\n",
        "@function_tool\n",
        "def get_population(city: str) -> str:\n",
        "    \"\"\"Get population of a city.\"\"\"\n",
        "    time.sleep(0.6)  # Simulate database query\n",
        "    return f\"Population of {city}: 10 million\"\n",
        "\n",
        "print(\"Creating agent with 5 tools and PARALLEL CALLING enabled...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:39:44] ðŸŸ¢ AGENT STARTED: ParallelBot\n",
            "[19:39:45] ðŸ”§ TOOL STARTED: get_weather\n",
            "[19:39:45] ðŸ”§ TOOL STARTED: get_time\n",
            "[19:39:45] ðŸ”§ TOOL STARTED: calculate_sum\n",
            "[19:39:45] ðŸ”§ TOOL STARTED: calculate_product\n",
            "[19:39:46] âœ… TOOL FINISHED: get_weather â†’ Weather in Tokyo: Sunny, 20Â°C\n",
            "[19:39:46] âœ… TOOL FINISHED: get_time â†’ Time in Tokyo: 3:00 PM\n",
            "[19:39:46] âœ… TOOL FINISHED: calculate_sum â†’ 15\n",
            "[19:39:46] âœ… TOOL FINISHED: calculate_product â†’ 21\n",
            "[19:39:49] ðŸ”´ AGENT ENDED\n",
            "\n",
            "============================================================\n",
            "â±ï¸  TOTAL TIME: 5.09 seconds\n",
            "ðŸ“Š TOTAL EVENTS: 10\n",
            "============================================================\n",
            "\n",
            "FINAL ANSWER:\n",
            "Here are the answers to your questions:\n",
            "\n",
            "- The weather in Tokyo is sunny, 20Â°C.\n",
            "- The current time in Tokyo is 3:00 PM.\n",
            "- 5 + 10 = 15\n",
            "- 3 Ã— 7 = 21\n"
          ]
        }
      ],
      "source": [
        "events.clear()  # Reset events\n",
        "\n",
        "agent_parallel = Agent(\n",
        "    name=\"ParallelBot\",\n",
        "    instructions=\"You are helpful. Use tools to answer questions.\",\n",
        "    tools=[get_weather, get_time, calculate_sum, calculate_product, get_population],\n",
        "    hooks=DetailedHooks(),\n",
        "    model_settings=ModelSettings(\n",
        "        parallel_tool_calls=True  # â† ENABLE PARALLEL\n",
        "    )\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result = await Runner.run(\n",
        "    agent_parallel,\n",
        "    \"What's the weather and time in Tokyo? Also calculate 5+10 and 3*7\"\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"â±ï¸  TOTAL TIME: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"ðŸ“Š TOTAL EVENTS: {len(events)}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:40:15] ðŸŸ¢ AGENT STARTED: SequentialBot\n",
            "[19:40:16] ðŸ”§ TOOL STARTED: get_weather\n",
            "[19:40:17] âœ… TOOL FINISHED: get_weather â†’ Weather in Tokyo: Sunny, 20Â°C\n",
            "[19:40:19] ðŸ”§ TOOL STARTED: get_time\n",
            "[19:40:19] âœ… TOOL FINISHED: get_time â†’ Time in Tokyo: 3:00 PM\n",
            "[19:40:20] ðŸ”§ TOOL STARTED: calculate_sum\n",
            "[19:40:20] âœ… TOOL FINISHED: calculate_sum â†’ 15\n",
            "[19:40:21] ðŸ”§ TOOL STARTED: calculate_product\n",
            "[19:40:22] âœ… TOOL FINISHED: calculate_product â†’ 21\n",
            "[19:40:23] ðŸ”´ AGENT ENDED\n",
            "\n",
            "============================================================\n",
            "â±ï¸  TOTAL TIME: 7.41 seconds\n",
            "ðŸ“Š TOTAL EVENTS: 10\n",
            "============================================================\n",
            "\n",
            "FINAL ANSWER:\n",
            "Here are the answers to your questions:\n",
            "\n",
            "- Weather in Tokyo: Sunny, 20Â°C\n",
            "- Time in Tokyo: 3:00 PM\n",
            "- 5 + 10 = 15\n",
            "- 3 Ã— 7 = 21\n",
            "\n",
            "Let me know if you need more information!\n"
          ]
        }
      ],
      "source": [
        "events.clear()  # Reset events\n",
        "\n",
        "agent_sequential = Agent(\n",
        "    name=\"SequentialBot\",\n",
        "    instructions=\"You are helpful. Use tools to answer questions.\",\n",
        "    tools=[get_weather, get_time, calculate_sum, calculate_product, get_population],\n",
        "    hooks=DetailedHooks(),\n",
        "    model_settings=ModelSettings(\n",
        "        parallel_tool_calls=False  # â† DISABLE PARALLEL\n",
        "    )\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result = await Runner.run(\n",
        "    agent_sequential,\n",
        "    \"What's the weather and time in Tokyo? Also calculate 5+10 and 3*7\"\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"â±ï¸  TOTAL TIME: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"ðŸ“Š TOTAL EVENTS: {len(events)}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Created 20 tools\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, AgentHooks, RunContextWrapper, Runner, Tool, function_tool, ModelSettings\n",
        "\n",
        "# Create a tracking hook that counts\n",
        "class CountingHooks(AgentHooks):\n",
        "    def __init__(self):\n",
        "        self.tool_starts = 0\n",
        "        self.tool_ends = 0\n",
        "        self.active_tools = 0  # Tools currently running\n",
        "        self.max_concurrent = 0  # Max tools running at same time\n",
        "    \n",
        "    async def on_start(self, context: RunContextWrapper, agent: Agent):\n",
        "        print(f\"ðŸŸ¢ Agent started with {len(agent.tools)} available tools\\n\")\n",
        "    \n",
        "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool):\n",
        "        self.tool_starts += 1\n",
        "        self.active_tools += 1\n",
        "        \n",
        "        # Track maximum concurrent tools\n",
        "        if self.active_tools > self.max_concurrent:\n",
        "            self.max_concurrent = self.active_tools\n",
        "        \n",
        "        print(f\"ðŸ”§ #{self.tool_starts:3d} START: {tool.name:20s} | Active now: {self.active_tools}\")\n",
        "    \n",
        "    async def on_tool_end(self, context: RunContextWrapper, agent: Agent, tool: Tool, result: str):\n",
        "        self.tool_ends += 1\n",
        "        self.active_tools -= 1\n",
        "        print(f\"âœ… #{self.tool_ends:3d} END:   {tool.name:20s} | Active now: {self.active_tools}\")\n",
        "    \n",
        "    async def on_end(self, context: RunContextWrapper, agent: Agent, output):\n",
        "        print(f\"\\nðŸ”´ Agent ended\")\n",
        "        print(f\"ðŸ“Š Statistics:\")\n",
        "        print(f\"   Total tool calls: {self.tool_starts}\")\n",
        "        print(f\"   Max concurrent: {self.max_concurrent} tools running at once\")\n",
        "\n",
        "# Create 20 different tools (simulating many tools)\n",
        "tools_list = []\n",
        "for i in range(20):\n",
        "    @function_tool\n",
        "    def generic_tool(data: str) -> str:\n",
        "        f\"\"\"Tool number {i} that processes data.\"\"\"\n",
        "        time.sleep(0.1)  # Simulate work\n",
        "        return f\"Processed by tool {i}\"\n",
        "    \n",
        "    # Give each tool a unique name\n",
        "    generic_tool.name = f\"tool_{i:02d}\"\n",
        "    tools_list.append(generic_tool)\n",
        "\n",
        "print(f\"âœ“ Created {len(tools_list)} tools\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running agent with many tools in PARALLEL mode...\n",
            "\n",
            "======================================================================\n",
            "ðŸŸ¢ Agent started with 20 available tools\n",
            "\n",
            "ðŸ”§ #  1 START: tool_00              | Active now: 1\n",
            "ðŸ”§ #  2 START: tool_05              | Active now: 2\n",
            "ðŸ”§ #  3 START: tool_10              | Active now: 3\n",
            "ðŸ”§ #  4 START: tool_15              | Active now: 4\n",
            "âœ… #  1 END:   tool_00              | Active now: 3\n",
            "âœ… #  2 END:   tool_05              | Active now: 2\n",
            "âœ… #  3 END:   tool_10              | Active now: 1\n",
            "âœ… #  4 END:   tool_15              | Active now: 0\n",
            "\n",
            "ðŸ”´ Agent ended\n",
            "ðŸ“Š Statistics:\n",
            "   Total tool calls: 4\n",
            "   Max concurrent: 4 tools running at once\n",
            "======================================================================\n",
            "\n",
            "ðŸ“ˆ Maximum tools running at the same time: 4\n"
          ]
        }
      ],
      "source": [
        "hooks = CountingHooks()\n",
        "\n",
        "agent_many_tools = Agent(\n",
        "    name=\"ManyToolsBot\",\n",
        "    instructions=\"You are helpful. Use multiple tools to gather information.\",\n",
        "    tools=tools_list,\n",
        "    hooks=hooks,\n",
        "    model_settings=ModelSettings(\n",
        "        parallel_tool_calls=True  # Allow parallel execution\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Running agent with many tools in PARALLEL mode...\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = await Runner.run(\n",
        "    agent_many_tools,\n",
        "    \"Process data using tool_00, tool_05, tool_10, tool_15 simultaneously\"\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nðŸ“ˆ Maximum tools running at the same time: {hooks.max_concurrent}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generator: Certainly! Here are a few tagline options for a new product called **'Civic'** (If you provide more about what the product isâ€”car, app, service, etc.â€”I can make it even more specific):\n",
            "\n",
            "1. **\"Civic: Empowering Every Community.\"**\n",
            "2. **\"Civic: Connect. Collaborate. Create.\"**\n",
            "3. **\"Civic: Where Ideas Become Action.\"**\n",
            "4. **\"Civic: For People, By People.\"**\n",
            "5. **\"Civic: Your Voice, Your Impact.\"**\n",
            "\n",
            "Let me know what kind of product Civic is, and I'll tailor the tagline even more!\n",
            "judge: score=85 reasoning=\"The response provides a good set of generic tagline options for a product named 'Civic,' each appropriately focused on community, collaboration, and empowerment. The notes about tailoring based on more specific product information demonstrate awareness of context and willingness to refine. The content is clear, useful, and suitable as an initial step in branding work. However, it loses some points because the suggestions are somewhat generic due to the lack of product details (not the respondent's fault, but affects specificity and creativity). A perfect answer would include a bit more creativity or a probing question about brand values or target audience.\"\n",
            "Score: 85\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    score: int\n",
        "    reasoning: str\n",
        "\n",
        "generator = Agent(name=\"Generator\")\n",
        "judge = Agent(\n",
        "    name=\"Judge\", \n",
        "    output_type=Evaluation, \n",
        "    instructions=\"You have to evaluate the content and give a score between 0 and 100 and also reason about the score\"\n",
        "    )\n",
        "# Generate content\n",
        "content = await Runner.run(generator, \"Write a tagline for a new product called 'Civic'\")\n",
        "\n",
        "# Evaluate it\n",
        "evaluation = await Runner.run(judge, f\"Evaluate: {content.final_output}\")\n",
        "print(f\"generator: {content.final_output}\")\n",
        "print(f\"judge: {evaluation.final_output}\")\n",
        "print(f\"Score: {evaluation.final_output.score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "CodeInterpreterTool.__init__() missing 1 required positional argument: 'tool_config'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, WebSearchTool, CodeInterpreterTool\n\u001b[32m      3\u001b[39m agent = Agent(\n\u001b[32m      4\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mResearcher\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mResearch and analyze data.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     tools=[WebSearchTool(), \u001b[43mCodeInterpreterTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m     10\u001b[39m     agent,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFind Bitcoin price and calculate 30-day average\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
            "\u001b[31mTypeError\u001b[39m: CodeInterpreterTool.__init__() missing 1 required positional argument: 'tool_config'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
